\section{LLM-Powered Analysis for Cluster Paths}

Recent advances in large language models (LLMs) provide new opportunities for interpreting neural network behavior through the analysis of cluster paths. We introduce a systematic framework for leveraging LLMs to generate human-readable narratives and insights about the internal decision processes represented by cluster paths.

\subsection{LLM Integration Architecture}

Our framework integrates LLMs into the cluster path analysis pipeline through a modular architecture with three primary components:

\begin{enumerate}
    \item \textbf{Cluster Labeling}: LLMs analyze cluster centroids to generate meaningful semantic labels that describe the concepts each cluster might represent.
    \item \textbf{Path Narrative Generation}: LLMs create coherent narratives explaining how concepts evolve through the network as data points traverse different clusters.
    \item \textbf{Bias Audit}: LLMs analyze demographic statistics associated with paths to identify potential biases in model behavior.
\end{enumerate}

The architecture includes:

\begin{itemize}
    \item \textbf{Cache Management}: Responses are cached to enable efficient re-analysis and promote reproducibility
    \item \textbf{Prompt Optimization}: Specialized prompting techniques that improve consistency and relevance of generated content
    \item \textbf{Batch Processing}: Efficient parallel processing of multiple clusters and paths
    \item \textbf{Demography Integration}: Analysis of how cluster paths relate to demographic attributes
\end{itemize}

\subsection{Semantic Cluster Labels}

The cluster labeling process transforms abstract mathematical representations (centroids) into semantically meaningful concepts. LLMs analyze cluster properties—including centroid values, dominant features, and datapoint characteristics—to generate interpretable labels. For instance, in medical applications, clusters might be labeled as "High-Risk Elderly" or "Low Cardiovascular Stress" based on their statistical properties. This automated labeling provides immediate interpretability while maintaining consistency across analyses.

\subsection{Path Narratives}

The narrative generation process explains how concepts evolve as data traverses the network. These narratives provide several interpretability advantages:

\begin{enumerate}
    \item \textbf{Contextual Integration}: Incorporating cluster labels, convergent points, fragmentation scores, and demographic data creates multi-faceted narratives.
    \item \textbf{Conceptual Evolution}: Narratives explain how concepts transform and evolve through network layers.
    \item \textbf{Decision Process Insights}: Explanations reveal potential decision-making processes that might be occurring within the model.
    \item \textbf{Demographic Awareness}: Including demographic information ensures narratives consider fairness and bias implications.
\end{enumerate}

% Include generated path narratives (These are now superseded by the _report.tex files)
% \input{sections/generated/titanic_narratives} 
% \input{sections/generated/heart_narratives}

% \subsection{Bias Audit Results} % Entire subsection commented out
% 
% The bias audit component analyzes potential demographic biases in cluster paths, creating a comprehensive analysis that:
% 
% \begin{enumerate}
%     \item \textbf{Identifies Demographic Patterns}: Reveals which demographic factors most strongly influence clustering patterns.
%     \item \textbf{Quantifies Bias}: Uses statistical measures (Jensen-Shannon divergence) to quantify deviation from baseline demographic distributions.
%     \item \textbf{Highlights Problematic Paths}: Identifies specific paths with high bias scores for further investigation.
%     \item \textbf{Provides Mitigation Strategies}: Offers concrete recommendations for addressing identified biases.
% \end{enumerate}
% 
% % Include generated bias metrics
% \input{sections/generated/titanic_bias}
% \input{sections/generated/heart_bias}

% Note: Specific LLM-generated reports for case studies are included in their respective sections

\subsection{Integrating Metrics with Narratives}

The quantitative metrics defined in Section 3.6 (F, FC, CE, SA) are provided to the LLM as part of the prompt, enabling narrative explanations that tie qualitative descriptions to quantitative evidence. For example, the LLM can explain that "entropy drops sharply from layer 2 to layer 3, indicating that the network consolidates risk factors" or "the decreasing sub-space angles reveal progressive alignment between disease and healthy patient representations."


\begin{table}[h!]
\centering
\caption{Example layer-wise fragmentation metrics showing how different metrics capture complementary aspects of concept evolution.}
\label{tab:fragmentation_metrics_example}
\begin{tabular}{lcccc}
\toprule
Layer & $k^*$ & CE & SA ($^\circ$) & FC (path mean) \\
\midrule
Layer 1 & 2 & 0.722 & 16.3 & 0.096 \\
Layer 2 & 2 & 0.713 & 11.5 & 0.096 \\
Layer 3 & 2 & 0.711 &  7.8 & 0.096 \\
Output  & 2 & 0.702 &  3.1 & 0.096 \\
\bottomrule
\end{tabular}
\end{table}\footnote{In this example from a shallow network, the consistent FC value of 0.096 indicates stable cluster representations throughout. Low fragmentation coefficients suggest smooth concept evolution, with cluster centroids maintaining high similarity (approximately 90.4\% cosine similarity) between consecutive layers.}

\subsection{Advantages and Limitations}

\textbf{Advantages}:
\begin{enumerate}
    \item \textbf{Interpretable Insights}: Converts complex mathematical patterns into human-readable explanations.
    \item \textbf{Multi-level Analysis}: Provides insights at cluster, path, and system-wide levels.
    \item \textbf{Bias Detection}: Proactively identifies potential fairness concerns in model behavior.
    \item \textbf{Integration with Metrics}: Combines qualitative narratives with quantitative fragmentation and similarity metrics.
\end{enumerate}

\textbf{Limitations}:
\begin{enumerate}
    \item \textbf{Potential for Overinterpretation}: LLMs might ascribe meaning to patterns that are artifacts of the clustering process.
    \item \textbf{Domain Knowledge Gaps}: Analysis quality depends on the LLM's understanding of the specific domain.
    \item \textbf{Computational Cost}: Generating narratives for many paths can be resource-intensive.
    \item \textbf{Validation Challenges}: Verifying the accuracy of generated narratives requires domain expertise.
\end{enumerate}

% The following placeholder prose was part of an earlier draft and is now
% superseded by automatically generated cluster labels, narratives and bias
% tables inserted via \input.  To avoid contradictory text we comment it out.
\iffalse
Our experiments show that these narratives can effectively translate complex mathematical relationships into intuitive explanations that capture the essence of the model's internal behavior.

### 6.4 Bias Auditing Through LLMs
... (placeholder content removed) ...
\fi