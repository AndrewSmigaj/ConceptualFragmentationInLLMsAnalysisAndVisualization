\section{LLM-Powered Analysis for Cluster Paths}

Recent advances in large language models (LLMs) provide new opportunities for interpreting neural network behavior through the analysis of cluster paths. We introduce a systematic framework for leveraging LLMs to generate human-readable narratives and insights about the internal decision processes represented by cluster paths.

\subsection{LLM Integration Architecture}

Our framework integrates LLMs into the cluster path analysis pipeline through a modular architecture with three primary components:

\begin{enumerate}
    \item \textbf{Cluster Labeling}: LLMs analyze cluster centroids to generate meaningful semantic labels that describe the concepts each cluster might represent.
    \item \textbf{Path Narrative Generation}: LLMs create coherent narratives explaining how concepts evolve through the network as data points traverse different clusters.
    \item \textbf{Bias Audit}: LLMs analyze demographic statistics associated with paths to identify potential biases in model behavior.
\end{enumerate}

The architecture includes:

\begin{itemize}
    \item \textbf{Cache Management}: Responses are cached to enable efficient re-analysis and promote reproducibility
    \item \textbf{Prompt Optimization}: Specialized prompting techniques that improve consistency and relevance of generated content
    \item \textbf{Batch Processing}: Efficient parallel processing of multiple clusters and paths
    \item \textbf{Demography Integration}: Analysis of how cluster paths relate to demographic attributes
\end{itemize}

\subsection{Semantic Cluster Labels}

The cluster labeling process transforms abstract mathematical representations (centroids) into semantically meaningful concepts. LLMs analyze cluster properties—including centroid values, dominant features, and datapoint characteristics—to generate interpretable labels. For instance, in medical applications, clusters might be labeled as "High-Risk Elderly" or "Low Cardiovascular Stress" based on their statistical properties. This automated labeling provides immediate interpretability while maintaining consistency across analyses.

\subsection{Path Narratives and Holistic Analysis}

The narrative generation process represents a fundamental advancement in neural network interpretability, transforming abstract mathematical patterns into human-comprehensible stories about model behavior. Our framework leverages LLMs' unique capabilities to provide multi-level analysis that would be impossible through traditional methods alone.

\subsubsection{Core Narrative Generation Capabilities}

LLMs excel at synthesizing complex, multi-dimensional information into coherent explanations. When analyzing cluster paths, they provide:

\begin{enumerate}
    \item \textbf{Multi-Level Synthesis}: LLMs simultaneously process cluster statistics, path trajectories, fragmentation metrics, and demographic distributions to identify patterns that span multiple levels of abstraction. This holistic view reveals emergent behaviors invisible when examining components in isolation.
    
    \item \textbf{Contextual Pattern Recognition}: By analyzing hundreds of paths simultaneously, LLMs identify recurring patterns, anomalies, and systematic biases. They recognize when certain demographic groups consistently follow specific paths or when particular feature combinations trigger unexpected routing.
    
    \item \textbf{Narrative Coherence}: LLMs transform disconnected data points into flowing narratives that explain not just what happens, but why. They identify causal relationships, highlight decision boundaries, and explain how initial categorizations evolve into final predictions.
    
    \item \textbf{Domain-Aware Interpretation}: LLMs apply domain knowledge to generate contextually appropriate explanations. In medical applications, they relate cluster patterns to clinical concepts; in NLP tasks, they connect trajectories to linguistic phenomena.
\end{enumerate}

\subsubsection{Comprehensive Analysis Framework}

Our framework structures LLM analysis into five interconnected components:

\begin{enumerate}
    \item \textbf{Cluster Semantic Labeling}: LLMs analyze cluster centroids, member statistics, and distinguishing features to generate meaningful labels that capture each cluster's conceptual essence. These labels form the foundation for all subsequent narrative generation.
    
    \item \textbf{Individual Path Narratives}: For each archetypal path, LLMs create stories explaining the conceptual journey from input to output. These narratives integrate:
    \begin{itemize}
        \item Initial cluster characteristics and why inputs start there
        \item Transition logic explaining movement between clusters
        \item Convergence/divergence patterns and their implications
        \item Final predictions and their relationship to the path taken
    \end{itemize}
    
    \item \textbf{Comparative Path Analysis}: LLMs identify similarities and differences across paths, revealing:
    \begin{itemize}
        \item Common decision points where paths diverge
        \item Demographic or feature patterns that determine routing
        \item Unexpected convergences suggesting shared processing
        \item Path stability and its correlation with prediction confidence
    \end{itemize}
    
    \item \textbf{System-Wide Behavioral Insights}: By analyzing all paths collectively, LLMs uncover:
    \begin{itemize}
        \item Dominant processing strategies employed by the model
        \item Hierarchical feature importance across layers
        \item Systematic biases in path assignment
        \item Emergent organizational principles
    \end{itemize}
    
    \item \textbf{Holistic Synthesis Reports}: LLMs generate comprehensive reports that weave individual findings into unified explanations of model behavior. These reports connect quantitative metrics (F, FC, CE, SA from Section 3.6) with qualitative insights to provide actionable understanding.
\end{enumerate}

\subsubsection{Narrative Value Beyond Traditional Analysis}

LLM-powered narratives provide unique value that complements quantitative metrics:

\begin{itemize}
    \item \textbf{Accessibility}: Technical metrics become understandable to non-experts through story-based explanations
    \item \textbf{Actionability}: Narratives suggest specific interventions for bias mitigation or performance improvement
    \item \textbf{Trustworthiness}: Explanations that align with domain knowledge build stakeholder confidence
    \item \textbf{Discovery}: LLMs identify unexpected patterns humans might miss in raw data
\end{itemize}

% Include generated path narratives (These are now superseded by the _report.tex files)
% \input{sections/generated/titanic_narratives} 
% \input{sections/generated/heart_narratives}

% \subsection{Bias Audit Results} % Entire subsection commented out
% 
% The bias audit component analyzes potential demographic biases in cluster paths, creating a comprehensive analysis that:
% 
% \begin{enumerate}
%     \item \textbf{Identifies Demographic Patterns}: Reveals which demographic factors most strongly influence clustering patterns.
%     \item \textbf{Quantifies Bias}: Uses statistical measures (Jensen-Shannon divergence) to quantify deviation from baseline demographic distributions.
%     \item \textbf{Highlights Problematic Paths}: Identifies specific paths with high bias scores for further investigation.
%     \item \textbf{Provides Mitigation Strategies}: Offers concrete recommendations for addressing identified biases.
% \end{enumerate}
% 
% % Include generated bias metrics
% \input{sections/generated/titanic_bias}
% \input{sections/generated/heart_bias}

% Note: Specific LLM-generated reports for case studies are included in their respective sections

\subsection{Integrating Metrics with Narratives}

The quantitative metrics defined in Section 3.6 (F, FC, CE, SA) are provided to the LLM as part of the prompt, enabling narrative explanations that tie qualitative descriptions to quantitative evidence. For example, the LLM can explain that "CE drops sharply from layer 2 to layer 3, indicating that the network consolidates risk factors" or "the decreasing SA values reveal progressive alignment between disease and healthy patient representations."


\begin{table}[h!]
\centering
\caption{Example layer-wise fragmentation metrics (see Section 3.6 for definitions) showing how different metrics capture complementary aspects of concept evolution.}
\label{tab:fragmentation_metrics_example}
\begin{tabular}{lcccc}
\toprule
Layer & $k^*$ & CE & SA ($^\circ$) & FC (path mean) \\
\midrule
Layer 1 & 2 & 0.722 & 16.3 & 0.096 \\
Layer 2 & 2 & 0.713 & 11.5 & 0.096 \\
Layer 3 & 2 & 0.711 &  7.8 & 0.096 \\
Output  & 2 & 0.702 &  3.1 & 0.096 \\
\bottomrule
\end{tabular}
\end{table}\footnote{In this example from a shallow network, the consistent FC value of 0.096 indicates stable cluster representations throughout. Low fragmentation coefficients suggest smooth concept evolution, with cluster centroids maintaining high similarity (approximately 90.4\% cosine similarity) between consecutive layers.}

\subsection{Advantages and Limitations}

\textbf{Advantages}:
\begin{enumerate}
    \item \textbf{Interpretable Insights}: Converts complex mathematical patterns into human-readable explanations.
    \item \textbf{Multi-level Analysis}: Provides insights at cluster, path, and system-wide levels.
    \item \textbf{Bias Detection}: Proactively identifies potential fairness concerns in model behavior.
    \item \textbf{Integration with Metrics}: Combines qualitative narratives with quantitative fragmentation and similarity metrics.
\end{enumerate}

\textbf{Limitations}:
\begin{enumerate}
    \item \textbf{Potential for Overinterpretation}: LLMs might ascribe meaning to patterns that are artifacts of the clustering process.
    \item \textbf{Domain Knowledge Gaps}: Analysis quality depends on the LLM's understanding of the specific domain.
    \item \textbf{Computational Cost}: Generating narratives for many paths can be resource-intensive.
    \item \textbf{Validation Challenges}: Verifying the accuracy of generated narratives requires domain expertise.
\end{enumerate}

% The following placeholder prose was part of an earlier draft and is now
% superseded by automatically generated cluster labels, narratives and bias
% tables inserted via \input.  To avoid contradictory text we comment it out.
\iffalse
Our experiments show that these narratives can effectively translate complex mathematical relationships into intuitive explanations that capture the essence of the model's internal behavior.

### 6.4 Bias Auditing Through LLMs
... (placeholder content removed) ...
\fi