\section{Introduction}

Interpretability research often struggles to balance rigor and accessibility, oscillating between visually compelling but loosely grounded ``quasi-explanations'' and mathematically sound but opaque theoretical analyses. Concept Trajectory Analysis (CTA) aims to bridge this gap by clustering datapoint activations at each layer of a trained network and tracing their transitions through activation space. This approach provides both mathematical precision and intuitive understanding of how neural networks process information, but its utility depends on addressing several foundational questions:

\begin{itemize}
    \item What makes activation geometry suitable for clustering?
    \item Under what transformations are cluster paths stable?
    \item Do cluster paths reflect genuine semantic or decision-relevant structure?
    \item How can we translate mathematical patterns into domain-meaningful explanations?
\end{itemize}

The challenge of translating quantitative patterns into qualitative understanding is particularly acute. While metrics like silhouette scores or mutual information can validate clustering quality, they offer limited insight into the semantic meaning of identified patterns. Our work introduces a novel approach to this problem by leveraging large language models (LLMs) to generate human-readable narratives that explain the conceptual significance of activation patterns.

We demonstrate this methodology through groundbreaking case studies analyzing GPT-2's internal representations. Our semantic pivot analysis reveals how transformer models process contradictory information. Most remarkably, our semantic subtypes study—examining 566 validated words across 8 semantic categories—discovered that GPT-2 organizes language by grammatical function rather than semantic meaning. Through our novel ``Concept MRI'' visualization, we found that 72.8\% of all words converge to a single ``noun superhighway,'' with animals and objects processed identically despite semantic differences. This counterintuitive finding challenges fundamental assumptions about how neural language models organize information.

\textbf{Contributions}:
\begin{itemize}
    \item Formalize activation-space geometry for datapoint clustering with layer-specific labels and mathematical validation criteria
    \item Introduce ETS-based clustering for dimension-wise explainability with verbalizably transparent membership conditions
    \item Develop cross-layer metrics (centroid similarity, membership overlap, fragmentation scores) to quantify concept evolution
    \item Propose a reproducible framework for path stability assessment using statistical robustness measures (ARI, MI, null models)
    \item Implement LLM-powered analysis to generate human-readable explanations of cluster paths
    \item \textbf{Discover grammatical organization in GPT-2}: First empirical evidence that transformers organize by syntax not semantics
    \item \textbf{Introduce ``Concept MRI'' visualization}: Novel technique for tracking concept flow through neural networks
    \item \textbf{Reveal massive convergence patterns}: 72.8\% of words converge to unified grammatical pipelines
    \item \textbf{Identify phase transitions}: Stability analysis reveals critical reorganization points in neural processing
    \item Demonstrate bias detection capabilities through demographic analysis of paths
    \item Provide an open-source implementation blueprint for application across diverse domains
\end{itemize}