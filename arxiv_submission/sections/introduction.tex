\section{Introduction}

Understanding how neural networks organize linguistic information remains a fundamental challenge in interpretability research. We present Concept Trajectory Analysis (CTA), a method that tracks concept evolution through neural networks by analyzing movement patterns in clustered activation spaces. Application of this method to GPT-2 indicates that the model organizes words primarily by grammatical function rather than semantic similarity, providing new insights into transformer language processing.

\begin{table}[h!]
\centering
\caption{Key Terminology Used in This Paper}
\label{tab:glossary}
\begin{tabular}{ll}
\toprule
\textbf{Term} & \textbf{Definition} \\
\midrule
Trajectory & The path a concept takes through cluster assignments across layers \\
Path & A specific sequence of clusters, e.g., L1\_C0→L2\_C1→L3\_C0 \\
Highway & A meso-level bundle of similar paths traveled by many concepts \\
Window & Temporal grouping of layers (Early: L0-3, Middle: L4-7, Late: L8-11) \\
F & Trajectory Fragmentation (see Section 3.6) \\
FC & Path-Centroid Fragmentation (see Section 3.6) \\
CE & Intra-Class Cluster Entropy (see Section 3.6) \\
SA & Sub-space Angle (see Section 3.6) \\
Microcluster & Fine-grained sub-structure within larger cluster (future work) \\
\bottomrule
\end{tabular}
\end{table}

Our analysis of 1,228 single-token words across 8 semantic categories reveals that GPT-2 develops a hierarchical organization strategy. Words initially cluster by semantic similarity in early layers, undergo a phase transition in middle layers, and converge to grammatical organization in later layers. This sequential reorganization—where a substantial portion of words ultimately follow common grammatical pathways—suggests that neural networks may first process semantic features before discovering grammatical function as an efficient organizing principle.

This observation emerged from our framework that combines mathematical analysis with human interpretation. CTA tracks concepts through clustered activation spaces across neural network layers, using quantitative metrics alongside LLM-generated explanations. The method offers five core capabilities:

\begin{itemize}
    \item \textbf{Dynamic analysis}: Tracking concept evolution through layers rather than static snapshots
    \item \textbf{Organizational insights}: Revealing principles like grammatical convergence in language models
    \item \textbf{Multi-scale understanding}: From individual trajectories to population-level patterns
    \item \textbf{Actionable interpretability}: Identifying bias patterns, uncertainty indicators, and decision pathways
    \item \textbf{Narrative explanations}: Bridging mathematical analysis with human comprehension through LLM integration
\end{itemize}

We validate CTA through experiments on both language models and traditional ML. Our windowed analysis (Early/Middle/Late) identifies phase transitions in neural processing, while unique cluster labeling (L\{layer\}\_C\{cluster\}) enables precise tracking. By analyzing all trajectories rather than just dominant paths, we capture the full complexity of neural organization.

Beyond transformer analysis, CTA can be applied to traditional ML tasks. In heart disease diagnosis, trajectory analysis shows how neural networks process patient data, with different pathways emerging for various patient profiles. High-risk patients (older, elevated cholesterol) tend to route through specific neural pathways with higher fragmentation scores (see Section 3.6), potentially indicating model uncertainty. This medical AI application illustrates how CTA can help understand decision-making processes in healthcare domains.

\subsection{Background: Concept Trajectory Analysis}

Concept Trajectory Analysis (CTA) clusters datapoint activations in each layer's activation space (e.g., using k-means), assigning layer-specific cluster IDs denoted L$l$\_C$k$, where $l$ is the layer index and $k$ is the cluster index. Transitions between clusters are tracked across layers, forming trajectories $\pi_i = [c_i^1, c_i^2, \dots, c_i^L]$, interpreted as concept evolution through the network. In feedforward networks, trajectories are strictly unidirectional, and clusters with different layer-specific IDs (e.g., L1\_C0 and L3\_C0) are not assumed related unless validated by geometric similarity metrics. Large language models can then narrate these trajectories to provide interpretable insights.

While activation spaces are emergent, high-dimensional representations whose coordinate systems may not map to semantically meaningful axes \citep{ribeiro2016, lundberg2017}, CTA addresses these concerns through rigorous mathematical validation and cross-layer metrics that verify genuine patterns rather than artifacts.

\textbf{Contributions}:
\begin{itemize}
    \item Formalize Concept Trajectory Analysis with mathematical validation criteria and cross-layer metrics
    \item Develop optimal clustering determination using Gap statistic with layer-specific cluster counts
    \item Implement trajectory visualization and LLM-powered interpretability for neural network analysis
    \item Provide evidence that GPT-2 organizes words primarily by grammatical function in later layers
    \item Demonstrate CTA's applicability to both transformer models and traditional ML tasks
    \item Release open-source implementation for reproducible neural network interpretability research
\end{itemize}