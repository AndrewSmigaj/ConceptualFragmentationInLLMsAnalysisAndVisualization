\begin{abstract}
Concept Trajectory Analysis (CTA) interprets neural networks by tracking datapoints through clustered activation spaces across layers. While initial experiments reveal meaningful internal structure, fairness dynamics, and decision heuristics, CTA's mathematical foundation requires formalization. We address this gap by establishing geometric and statistical principles for activation-space clustering validity, analyzing sensitivity to distance metrics and parameters, and incorporating Explainable Threshold Similarity (ETS, $\tau_j$) for transparent cluster definitions. Our framework relates latent trajectories to established notions of similarity and information flow, ensuring clarity in feedforward networks through layer-specific cluster labels and geometric similarity validation. We introduce cross-layer metrics including centroid similarity ($\rho^c$), membership overlap ($J$), and trajectory fragmentation ($F$) to quantify conceptual evolution. Our key innovation is the integration of large language models (LLMs) to generate human-readable narratives that explain concept trajectories, providing domain-meaningful interpretation of computational patterns. Experimental results on Titanic and Heart Disease datasets, along with comprehensive GPT-2 transformer analysis, demonstrate that LLM-powered CTA can identify nuanced decision processes, semantic organization patterns, and potential biases that might otherwise remain opaque, bridging the gap between mathematical rigor and human understanding.

\textbf{Research Question} --- One-Sentence Focus: Under what geometric and statistical conditions do layerwise activation clusters form stable, semantically meaningful concept trajectories that can be used for faithful model interpretation?
\end{abstract}