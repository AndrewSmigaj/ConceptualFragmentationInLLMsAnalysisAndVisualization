\begin{abstract}
We present Concept Trajectory Analysis (CTA), an interpretability method that tracks how neural networks organize concepts by following their paths through clustered activation spaces across layers. Applying CTA to GPT-2 with 1,228 single-token words revealed that the model organizes language primarily by grammatical function rather than semantic meaning, with 48.5\% of words converging to common grammatical pathways where nouns—whether animals, objects, or abstracts—travel together, while maintaining semantic distinctions at finer scales ($\chi^2 = 95.90$, $p < 0.0001$).

CTA quantifies concept flow through networks by combining geometric clustering with trajectory tracking. Key innovations include windowed analysis for phase transition detection (semantic→grammatical in GPT-2) and LLM-powered interpretation. In medical AI, CTA exposed patient risk stratification pathways and demographic biases (male overprediction in Path 4, 83\% male composition).

By making neural organization visible and quantifiable, CTA advances interpretable AI through dynamic analysis, organizational insights, and actionable interpretability. Our open-source implementation enables researchers to apply CTA across domains.
\end{abstract}