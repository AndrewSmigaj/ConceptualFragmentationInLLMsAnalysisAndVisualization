\begin{abstract}
We present Concept Trajectory Analysis (CTA), an interpretability method that tracks how concepts move through clustered activation spaces in neural networks. Applying CTA to GPT-2, we analyzed 1,228 single-token words across 8 semantic categories with balanced grammatical representation (33.1\% verbs). We observed that 48.5\% (95\% CI: 45.7\%–51.2\%) of words converge to a dominant pathway we term the ``entity superhighway,'' where nouns cluster together regardless of whether they represent animals, objects, or abstract concepts. This pattern, validated by highly significant grammatical clustering ($\chi^2 = 95.90$, $p < 0.0001$), demonstrates that GPT-2 uses grammatical function as its primary organizing principle while maintaining semantic distinctions within these grammatical pathways. 

CTA combines mathematical rigor with human interpretability: we formalize geometric conditions for valid clustering, introduce windowed analysis (Early/Middle/Late) that reveals phase transitions in neural processing, and employ unique cluster labeling (L\{layer\}\_C\{cluster\}) to track concept evolution precisely. Our framework quantifies path diversity through trajectory fragmentation metrics while leveraging LLMs to generate interpretable cluster labels and insights.

Beyond transformer analysis, we applied CTA to traditional ML tasks. In heart disease diagnosis, trajectory analysis shows how models process patient data through distinct pathways. Different patient profiles—distinguished by age, cholesterol, and clinical markers—tend to follow different neural pathways, with path fragmentation potentially indicating diagnostic uncertainty. This application demonstrates CTA's utility for understanding model decision-making in healthcare contexts. By providing visibility into neural network organization, CTA offers a tool for model interpretation that could be useful for debugging and analysis.

\textbf{Research Question} --- One-Sentence Focus: Under what geometric and statistical conditions do layerwise activation clusters form stable, semantically meaningful concept trajectories that can be used for faithful model interpretation?
\end{abstract}