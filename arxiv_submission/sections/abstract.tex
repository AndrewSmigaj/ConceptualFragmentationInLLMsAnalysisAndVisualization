\begin{abstract}
Archetypal Path Analysis (APA) interprets neural networks by tracking datapoints through clustered activation spaces across layers. While initial experiments reveal meaningful internal structure, fairness dynamics, and decision heuristics, APA's mathematical foundation requires formalization. We address this gap by establishing geometric and statistical principles for activation-space clustering validity, analyzing sensitivity to distance metrics and parameters, and incorporating Explainable Threshold Similarity (ETS, $\tau_j$) for transparent cluster definitions. Our framework relates latent trajectories to established notions of similarity and information flow, ensuring clarity in feedforward networks through layer-specific cluster labels and geometric similarity validation. We introduce cross-layer metrics including centroid similarity ($\rho^c$), membership overlap ($J$), and trajectory fragmentation ($F$) to quantify conceptual evolution. Our key innovation is the integration of large language models (LLMs) to generate human-readable narratives that explain paths, providing domain-meaningful interpretation of computational patterns. Experimental results on Titanic and Heart Disease datasets demonstrate that LLM-powered analysis can identify nuanced decision processes and potential biases that might otherwise remain opaque, bridging the gap between mathematical rigor and human understanding.

\textbf{Research Question} --- One-Sentence Focus: Under what geometric and statistical conditions do layerwise activation clusters form stable, semantically meaningful archetypal paths that can be used for faithful model interpretation?
\end{abstract}